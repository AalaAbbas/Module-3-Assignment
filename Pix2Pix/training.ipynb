{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pix2Pix Training \n",
    "Implementation based on https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix\n",
    "Developed by David DÃ³ria https://github.com/daversd for\n",
    "2021-2022 B-pro Architectural Design RC4\n",
    "\n",
    "Pix2Pix is a conditional genrative adversarial network model that performs image-to-image translations, learning how to do this operation from a data set of image pairs (input and expected outputs). This implementation uses `256x256 px` images for input and output, expecting training set to be formatted already in a folder that contains `/AB/train/` and `AB/test/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.onnx\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pix2pix_helpers.util as util\n",
    "from pix2pix_helpers.create_dataset import ImageFolderLoader\n",
    "from pix2pix_helpers.pix2pix_model import Pix2PixModel\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import glob"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2a823281cdc9ab4784167ce518d6e3821034e8b9fd5790a1e85c63b153d6503e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('torch-ready': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
